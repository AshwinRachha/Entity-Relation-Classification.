{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP HW2 Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMDi5zpyKEBq",
        "outputId": "ee51dcbc-fc1b-45af-f4bd-c4fe93bf2963"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqzRD26oKatA",
        "outputId": "90442c34-72e2-408e-fe49-c8b71473a043"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path('/content/gdrive/My Drive/NLP')\n",
        "os.listdir(path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nyt29.zip', 'Dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1ejS902Kxb2"
      },
      "source": [
        "extract_path = '/content/gdrive/My Drive/NLP/nyt29.zip'\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(extract_path, 'r') as zipref:\n",
        "  zipref.extractall('/content/gdrive/My Drive/NLP/Dataset')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6OEuVgbLUOV",
        "outputId": "b5c7d9b7-3c7b-4d97-f14f-6928bd4dee71"
      },
      "source": [
        "os.listdir('/content/gdrive/My Drive/NLP/Dataset')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dev.pointer',\n",
              " 'test.pointer',\n",
              " 'train.pointer',\n",
              " '__MACOSX',\n",
              " 'train_df2.gz',\n",
              " 'val_df2.gz',\n",
              " 'dev.sent',\n",
              " 'dev.tup',\n",
              " 'relations.txt',\n",
              " 'test.sent',\n",
              " 'test.tup',\n",
              " 'train.sent',\n",
              " 'train.tup',\n",
              " 'Best_model.h5py']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlcLTXbbL3oq"
      },
      "source": [
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sys\n",
        "dir_path ='/content/gdrive/My Drive/NLP/Dataset'\n",
        "path = Path(dir_path)\n",
        "sys.path.append(dir_path)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.corpus import stopwords \n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import pickle\n",
        "import math\n",
        "import torch.optim as optim\n",
        "import datetime\n",
        "import torch.autograd as autograd\n",
        "from tqdm import tqdm,trange\n",
        "import ast\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKU_hFynMbKx",
        "outputId": "5a774e79-f4f3-4819-b593-2f606e1f7988"
      },
      "source": [
        "file = open(\"{}/train.sent\".format(dir_path), encoding=\"utf8\").read()\n",
        "\n",
        "all_sentences = []\n",
        "for ind, line in enumerate(file.split('\\n')):\n",
        "    all_sentences.append(line)\n",
        "all_sentences = all_sentences[:-1]\n",
        "#to dataframe\n",
        "train = pd.DataFrame({'Sentences':all_sentences})\n",
        "print(train.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Sentences\n",
            "0  then terrorism struck again , this time in the...\n",
            "1  a12 new york\\/region b1-7 enclave for middle c...\n",
            "2  before long , though , he 's continent-hopping...\n",
            "3  general casey said the iraqi forces had little...\n",
            "4  84 , of avon , connecticut and longboat key , ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJVQD7KWMbiv",
        "outputId": "39228b99-bb37-4841-b7bd-1dacf142f32e"
      },
      "source": [
        "file = open(\"{}/dev.sent\".format(dir_path), encoding=\"utf8\").read()\n",
        "\n",
        "all_sentences = []\n",
        "for ind, line in enumerate(file.split('\\n')):\n",
        "    all_sentences.append(line)\n",
        "all_sentences = all_sentences[:-1]\n",
        "#to dataframe\n",
        "val = pd.DataFrame({'Sentences':all_sentences})\n",
        "print(val.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Sentences\n",
            "0  mr. scruggs -- who is arguing the case with hi...\n",
            "1  officials in new delhi have even printed a glo...\n",
            "2  new york city , pierson convincingly argues , ...\n",
            "3  ` the wizard of oz , ' a musical by the new yo...\n",
            "4  among their notable first-day selections were ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG0Nt18dMbxJ",
        "outputId": "3b6e9d49-a67b-4d9c-b349-b631db504890"
      },
      "source": [
        "file = open(\"{}/train.pointer\".format(dir_path), encoding=\"utf8\").read()\n",
        "df_relations_list = []\n",
        "for ind, line in enumerate(file.split('\\n')):\n",
        "    if(line.strip()==\"\"):\n",
        "      continue\n",
        "    relations = line.split('| ')\n",
        "    relations_list = []\n",
        "    for relation in relations:\n",
        "      relation_dict = dict()\n",
        "      relation_word_list = relation.split(' ')\n",
        "      \n",
        "      relation_dict['entity1_start_index'] = relation_word_list[0]\n",
        "      relation_dict['entity1_end_index'] = relation_word_list[1]\n",
        "      relation_dict['entity2_start_index'] = relation_word_list[2]\n",
        "      relation_dict['entity2_end_index'] = relation_word_list[3]\n",
        "      relation_dict['relation'] = relation_word_list[4]\n",
        "\n",
        "      relations_list.append(relation_dict)\n",
        "    \n",
        "    df_relations_list.append(relations_list)\n",
        "    # print(relations_list)\n",
        "    # break\n",
        "\n",
        "train['relation_pointers'] = pd.Series(df_relations_list)\n",
        "\n",
        "train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(63306, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQVR9FR-McDI",
        "outputId": "1fdf5247-12ce-4d69-bab2-654ccf4c37cb"
      },
      "source": [
        "file = open(\"{}/dev.pointer\".format(dir_path), encoding=\"utf8\").read()\n",
        "df_relations_list = []\n",
        "for ind, line in enumerate(file.split('\\n')):\n",
        "    if(line.strip()==\"\"):\n",
        "      continue\n",
        "    relations = line.split('| ')\n",
        "    relations_list = []\n",
        "    for relation in relations:\n",
        "      relation_dict = dict()\n",
        "      relation_word_list = relation.split(' ')\n",
        "      \n",
        "      relation_dict['entity1_start_index'] = relation_word_list[0]\n",
        "      relation_dict['entity1_end_index'] = relation_word_list[1]\n",
        "      relation_dict['entity2_start_index'] = relation_word_list[2]\n",
        "      relation_dict['entity2_end_index'] = relation_word_list[3]\n",
        "      relation_dict['relation'] = relation_word_list[4]\n",
        "\n",
        "      relations_list.append(relation_dict)\n",
        "    \n",
        "    df_relations_list.append(relations_list)\n",
        "    # print(relations_list)\n",
        "    # break\n",
        "\n",
        "val['relation_pointers'] = pd.Series(df_relations_list)\n",
        "\n",
        "val.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7033, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkoJFjq7NF45"
      },
      "source": [
        "file = open(\"{}/train.tup\".format(dir_path), encoding=\"utf8\").read()\n",
        "df_relations_list = []\n",
        "for ind, line in enumerate(file.split('\\n')):\n",
        "    # print(line)\n",
        "    if(line.strip()==\"\"):\n",
        "      continue\n",
        "    relations = line.split('| ')\n",
        "    relations_list = []\n",
        "    for relation in relations:\n",
        "      # print(relation)\n",
        "      relation_dict = dict()\n",
        "      relation_word_list = relation.split(' ; ')\n",
        "      # print(relation_word_list)\n",
        "      relation_dict['entity1_word'] = relation_word_list[0]\n",
        "      relation_dict['entity2_word'] = relation_word_list[1]\n",
        "      relation_dict['relation'] = relation_word_list[2].strip()\n",
        "\n",
        "      relations_list.append(relation_dict)\n",
        "    \n",
        "    df_relations_list.append(relations_list)\n",
        "    # print(relations_list)\n",
        "    # break\n",
        "\n",
        "train['relation_tuples'] = pd.Series(df_relations_list)\n",
        "\n",
        "#creating relations column : 1\n",
        "file = open(\"{}/dev.tup\".format(dir_path), encoding=\"utf8\").read()\n",
        "df_relations_list = []\n",
        "for ind, line in enumerate(file.split('\\n')):\n",
        "    # print(line)\n",
        "    if(line.strip()==\"\"):\n",
        "      continue\n",
        "    relations = line.split('| ')\n",
        "    relations_list = []\n",
        "    for relation in relations:\n",
        "      # print(relation)\n",
        "      relation_dict = dict()\n",
        "      relation_word_list = relation.split(' ; ')\n",
        "      # print(relation_word_list)\n",
        "      relation_dict['entity1_word'] = relation_word_list[0]\n",
        "      relation_dict['entity2_word'] = relation_word_list[1]\n",
        "      relation_dict['relation'] = relation_word_list[2].strip()\n",
        "\n",
        "      relations_list.append(relation_dict)\n",
        "    \n",
        "    df_relations_list.append(relations_list)\n",
        "    # print(relations_list)\n",
        "    # break\n",
        "\n",
        "val['relation_tuples'] = pd.Series(df_relations_list)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Br5lv8WhmUoy",
        "outputId": "f1c80f30-68d6-470d-93c3-61bf1e4a9da7"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>relation_pointers</th>\n",
              "      <th>relation_tuples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>then terrorism struck again , this time in the...</td>\n",
              "      <td>[{'entity1_start_index': '12', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'jakarta', 'entity2_word': '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a12 new york\\/region b1-7 enclave for middle c...</td>\n",
              "      <td>[{'entity1_start_index': '16', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'stuyvesant town', 'entity2_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>before long , though , he 's continent-hopping...</td>\n",
              "      <td>[{'entity1_start_index': '29', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'spain', 'entity2_word': 'pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>general casey said the iraqi forces had little...</td>\n",
              "      <td>[{'entity1_start_index': '15', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'syria', 'entity2_word': 'eu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84 , of avon , connecticut and longboat key , ...</td>\n",
              "      <td>[{'entity1_start_index': '10', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'florida', 'entity2_word': '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences  ...                                    relation_tuples\n",
              "0  then terrorism struck again , this time in the...  ...  [{'entity1_word': 'jakarta', 'entity2_word': '...\n",
              "1  a12 new york\\/region b1-7 enclave for middle c...  ...  [{'entity1_word': 'stuyvesant town', 'entity2_...\n",
              "2  before long , though , he 's continent-hopping...  ...  [{'entity1_word': 'spain', 'entity2_word': 'pa...\n",
              "3  general casey said the iraqi forces had little...  ...  [{'entity1_word': 'syria', 'entity2_word': 'eu...\n",
              "4  84 , of avon , connecticut and longboat key , ...  ...  [{'entity1_word': 'florida', 'entity2_word': '...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "1u3JeG0eNW4P",
        "outputId": "1eea0700-d6d9-4a00-b2ec-047b7d8401b5"
      },
      "source": [
        "val.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>relation_pointers</th>\n",
              "      <th>relation_tuples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mr. scruggs -- who is arguing the case with hi...</td>\n",
              "      <td>[{'entity1_start_index': '50', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'trent lott', 'entity2_word'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>officials in new delhi have even printed a glo...</td>\n",
              "      <td>[{'entity1_start_index': '15', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'india', 'entity2_word': 'ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new york city , pierson convincingly argues , ...</td>\n",
              "      <td>[{'entity1_start_index': '23', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'ulster county', 'entity2_wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>` the wizard of oz , ' a musical by the new yo...</td>\n",
              "      <td>[{'entity1_start_index': '11', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'new york', 'entity2_word': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>among their notable first-day selections were ...</td>\n",
              "      <td>[{'entity1_start_index': '63', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'jesse barfield', 'entity2_w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences  ...                                    relation_tuples\n",
              "0  mr. scruggs -- who is arguing the case with hi...  ...  [{'entity1_word': 'trent lott', 'entity2_word'...\n",
              "1  officials in new delhi have even printed a glo...  ...  [{'entity1_word': 'india', 'entity2_word': 'ne...\n",
              "2  new york city , pierson convincingly argues , ...  ...  [{'entity1_word': 'ulster county', 'entity2_wo...\n",
              "3  ` the wizard of oz , ' a musical by the new yo...  ...  [{'entity1_word': 'new york', 'entity2_word': ...\n",
              "4  among their notable first-day selections were ...  ...  [{'entity1_word': 'jesse barfield', 'entity2_w...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-ywKKA-NWqx",
        "outputId": "fd6d96b1-62d3-4ad7-e7d4-a780c24df19e"
      },
      "source": [
        "train.loc[0,'relation_tuples']\n",
        "val.loc[0,'relation_tuples']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity1_word': 'trent lott',\n",
              "  'entity2_word': 'mississippi',\n",
              "  'relation': '/people/person/place_lived'},\n",
              " {'entity1_word': 'gene taylor',\n",
              "  'entity2_word': 'bay st. louis',\n",
              "  'relation': '/people/person/place_lived'},\n",
              " {'entity1_word': 'trent lott',\n",
              "  'entity2_word': 'pascagoula',\n",
              "  'relation': '/people/person/place_lived'},\n",
              " {'entity1_word': 'gene taylor',\n",
              "  'entity2_word': 'mississippi',\n",
              "  'relation': '/people/person/place_lived'}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ8lCWpwNFnQ",
        "outputId": "d749f6a9-a25e-4230-84d1-25d9c530cdf3"
      },
      "source": [
        "def add_separators_to_sentence(sentence,first_entity_index_start,first_entity_index_end,second_entity_index_start,second_entity_index_end):\n",
        "  words = sentence.split()\n",
        "  words[first_entity_index_start] = '$ ' + words[first_entity_index_start]\n",
        "  words[first_entity_index_end] = words[first_entity_index_end] + ' $'\n",
        "  words[second_entity_index_start] = '# ' + words[second_entity_index_start]\n",
        "  words[second_entity_index_end] = words[second_entity_index_end] + ' #'\n",
        "\n",
        "  sentence_new = ' '.join(words)\n",
        "  return \"[CLS] \" + sentence_new\n",
        "\n",
        "# import re\n",
        "# input_file = \"africa african\"; \n",
        "# first_entity = 'africa'\n",
        "# a = re.sub(r'^' + first_entity, '$ africa $', input_file)\n",
        "# print(a)\n",
        "\n",
        "sent = 'The quick brown fox jumped over the lazy dog'\n",
        "print(add_separators_to_sentence(sent,3, 3, 8,8))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] The quick brown $ fox $ jumped over the lazy # dog #\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia7DF5-UNFag"
      },
      "source": [
        "def preprocess_sentences_to_bert_input(row):\n",
        "  sentence = row['Sentences']\n",
        "  tokens = sentence.split()\n",
        "\n",
        "  preprocessed_sentences = []\n",
        "  labels = []\n",
        "  entities = set()\n",
        "  entities_indices = set()\n",
        "  for index,relation in enumerate(row['relation_tuples']):\n",
        "    # print(relation)\n",
        "    entities.add(relation['entity1_word'])\n",
        "    entities_indices.add((row['relation_pointers'][index]['entity1_start_index'], row['relation_pointers'][index]['entity1_end_index']))\n",
        "    entities.add(relation['entity2_word'])\n",
        "    entities_indices.add((row['relation_pointers'][index]['entity2_start_index'], row['relation_pointers'][index]['entity2_end_index']))\n",
        "  \n",
        "  entities = list(entities)\n",
        "  entities_indices = list([[int(inner_item) for inner_item in item] for item in entities_indices])\n",
        "  # print(entities_indices)\n",
        "  for i in range(len(entities)):\n",
        "    for j in range(i+1,len(entities)):\n",
        "      relations = []\n",
        "      for index,relation in enumerate(row['relation_tuples']):\n",
        "        if(entities[i]==relation['entity1_word'] and entities[j]==relation['entity2_word']):\n",
        "          relations.append(relation['relation'])\n",
        "      preprocessed_sentence  = add_separators_to_sentence(sentence,entities_indices[i][0],entities_indices[i][1],entities_indices[j][0],entities_indices[j][1])\n",
        "      if(len(relations)==0):\n",
        "        relations.append(\"None\")\n",
        "      preprocessed_sentences.append(preprocessed_sentence)\n",
        "      labels.append(relations)\n",
        "\n",
        "      relations = []\n",
        "      for relation in row['relation_tuples']:\n",
        "        if(entities[j]==relation['entity1_word'] and entities[i]==relation['entity2_word']):\n",
        "          relations.append(relation['relation'])\n",
        "      preprocessed_sentence =  add_separators_to_sentence(sentence,entities_indices[j][0],entities_indices[j][1],entities_indices[i][0],entities_indices[i][1])\n",
        "      if(len(relations)==0):\n",
        "        relations.append(\"None\")\n",
        "      preprocessed_sentences.append(preprocessed_sentence)\n",
        "      labels.append(relations)\n",
        "\n",
        "  d = dict()\n",
        "  d['preprocessed_sentences'] = preprocessed_sentences\n",
        "  d['labels'] = labels\n",
        "  return d"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDHHybKfMcS5"
      },
      "source": [
        "train['preprocessed_sentences_labels'] = train.apply(preprocess_sentences_to_bert_input,axis=1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivzdCwTyN8q3"
      },
      "source": [
        "val['preprocessed_sentences_labels'] = val.apply(preprocess_sentences_to_bert_input,axis=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkvg1kFON9Cn",
        "outputId": "c35612b1-a813-4378-9231-5255c684f6df"
      },
      "source": [
        "train.loc[0,'preprocessed_sentences_labels']"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': [['/location/country/capital',\n",
              "   '/location/country/administrative_divisions'],\n",
              "  ['/location/administrative_division/country']],\n",
              " 'preprocessed_sentences': ['[CLS] then terrorism struck again , this time in the # indonesia # capital of $ jakarta $ .',\n",
              "  '[CLS] then terrorism struck again , this time in the $ indonesia $ capital of # jakarta # .']}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFRcBCgZN9UI",
        "outputId": "6747cc81-01bd-482f-8b49-c4bbeff5ee28"
      },
      "source": [
        "val.loc[0,'preprocessed_sentences_labels']"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': [['None'],\n",
              "  ['None'],\n",
              "  ['/people/person/place_lived'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['/people/person/place_lived'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['/people/person/place_lived'],\n",
              "  ['None'],\n",
              "  ['/people/person/place_lived'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['None'],\n",
              "  ['None']],\n",
              " 'preprocessed_sentences': ['[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern $ mississippi $ , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator # trent lott # , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative gene taylor of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern # mississippi # , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator $ trent lott $ , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative gene taylor of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern $ mississippi $ , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative # gene taylor # of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern # mississippi # , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative $ gene taylor $ of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern $ mississippi $ , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in # pascagoula # and his brother-in-law ; and representative gene taylor of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern # mississippi # , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in $ pascagoula $ and his brother-in-law ; and representative gene taylor of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern $ mississippi $ , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative gene taylor of # bay st. louis # .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern # mississippi # , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative gene taylor of $ bay st. louis $ .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator $ trent lott $ , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative # gene taylor # of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator # trent lott # , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative $ gene taylor $ of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator $ trent lott $ , who is both a neighbor of mr. scruggs in # pascagoula # and his brother-in-law ; and representative gene taylor of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator # trent lott # , who is both a neighbor of mr. scruggs in $ pascagoula $ and his brother-in-law ; and representative gene taylor of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator $ trent lott $ , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative gene taylor of # bay st. louis # .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator # trent lott # , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative gene taylor of $ bay st. louis $ .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in # pascagoula # and his brother-in-law ; and representative $ gene taylor $ of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in $ pascagoula $ and his brother-in-law ; and representative # gene taylor # of bay st. louis .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative $ gene taylor $ of # bay st. louis # .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in pascagoula and his brother-in-law ; and representative # gene taylor # of $ bay st. louis $ .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in $ pascagoula $ and his brother-in-law ; and representative gene taylor of # bay st. louis # .',\n",
              "  '[CLS] mr. scruggs -- who is arguing the case with his son zach ; a colleague from northern mississippi , don barrett ; and john jones from jackson , miss. -- said he had already filed suit on behalf of about 2,000 clients seeking redress from their insurers , including senator trent lott , who is both a neighbor of mr. scruggs in # pascagoula # and his brother-in-law ; and representative gene taylor of $ bay st. louis $ .']}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "B014lVHrN9tX",
        "outputId": "719ab7c8-5185-4b90-a1dd-f6e930731854"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>relation_pointers</th>\n",
              "      <th>relation_tuples</th>\n",
              "      <th>preprocessed_sentences_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>then terrorism struck again , this time in the...</td>\n",
              "      <td>[{'entity1_start_index': '12', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'jakarta', 'entity2_word': '...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] then terror...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a12 new york\\/region b1-7 enclave for middle c...</td>\n",
              "      <td>[{'entity1_start_index': '16', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'stuyvesant town', 'entity2_...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] a12 new yor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>before long , though , he 's continent-hopping...</td>\n",
              "      <td>[{'entity1_start_index': '29', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'spain', 'entity2_word': 'pa...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] before long...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>general casey said the iraqi forces had little...</td>\n",
              "      <td>[{'entity1_start_index': '15', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'syria', 'entity2_word': 'eu...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] general cas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84 , of avon , connecticut and longboat key , ...</td>\n",
              "      <td>[{'entity1_start_index': '10', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'florida', 'entity2_word': '...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] 84 , of avo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences  ...                      preprocessed_sentences_labels\n",
              "0  then terrorism struck again , this time in the...  ...  {'preprocessed_sentences': ['[CLS] then terror...\n",
              "1  a12 new york\\/region b1-7 enclave for middle c...  ...  {'preprocessed_sentences': ['[CLS] a12 new yor...\n",
              "2  before long , though , he 's continent-hopping...  ...  {'preprocessed_sentences': ['[CLS] before long...\n",
              "3  general casey said the iraqi forces had little...  ...  {'preprocessed_sentences': ['[CLS] general cas...\n",
              "4  84 , of avon , connecticut and longboat key , ...  ...  {'preprocessed_sentences': ['[CLS] 84 , of avo...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "bwcki8konihY",
        "outputId": "f94c037d-afc3-4fb5-ec54-74a6a125779f"
      },
      "source": [
        "val.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>relation_pointers</th>\n",
              "      <th>relation_tuples</th>\n",
              "      <th>preprocessed_sentences_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mr. scruggs -- who is arguing the case with hi...</td>\n",
              "      <td>[{'entity1_start_index': '50', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'trent lott', 'entity2_word'...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] mr. scruggs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>officials in new delhi have even printed a glo...</td>\n",
              "      <td>[{'entity1_start_index': '15', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'india', 'entity2_word': 'ne...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] officials i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new york city , pierson convincingly argues , ...</td>\n",
              "      <td>[{'entity1_start_index': '23', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'ulster county', 'entity2_wo...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] new york ci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>` the wizard of oz , ' a musical by the new yo...</td>\n",
              "      <td>[{'entity1_start_index': '11', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'new york', 'entity2_word': ...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] ` the wizar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>among their notable first-day selections were ...</td>\n",
              "      <td>[{'entity1_start_index': '63', 'entity1_end_in...</td>\n",
              "      <td>[{'entity1_word': 'jesse barfield', 'entity2_w...</td>\n",
              "      <td>{'preprocessed_sentences': ['[CLS] among their...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences  ...                      preprocessed_sentences_labels\n",
              "0  mr. scruggs -- who is arguing the case with hi...  ...  {'preprocessed_sentences': ['[CLS] mr. scruggs...\n",
              "1  officials in new delhi have even printed a glo...  ...  {'preprocessed_sentences': ['[CLS] officials i...\n",
              "2  new york city , pierson convincingly argues , ...  ...  {'preprocessed_sentences': ['[CLS] new york ci...\n",
              "3  ` the wizard of oz , ' a musical by the new yo...  ...  {'preprocessed_sentences': ['[CLS] ` the wizar...\n",
              "4  among their notable first-day selections were ...  ...  {'preprocessed_sentences': ['[CLS] among their...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_4sCXUMOVPY"
      },
      "source": [
        "train_2 = pd.DataFrame(columns=['sentence_index','sentence','preprocessed_sentence','labels'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzCcvc1FOVeH",
        "outputId": "40cd55a8-ac6f-41b3-df8e-93b1c02403fb"
      },
      "source": [
        "for index,row in tqdm(train.iterrows()):\n",
        "  temp = pd.DataFrame(columns=['sentence_index','sentence','preprocessed_sentence','labels'])\n",
        "  sentence = row['Sentences']\n",
        "  preprocessed_sentences = row['preprocessed_sentences_labels']['preprocessed_sentences']\n",
        "  labels = row['preprocessed_sentences_labels']['labels']\n",
        "  for i in range(len(labels)):\n",
        "    data = pd.Series({'sentence_index': index,'sentence':sentence,\"preprocessed_sentence\": preprocessed_sentences[i], \"labels\": labels[i]})\n",
        "    temp = temp.append(data,ignore_index=True)\n",
        "  \n",
        "  train_2 = train_2.append(temp,ignore_index = True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "63306it [19:29, 54.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCiSm75KOVtY"
      },
      "source": [
        "val_2 = pd.DataFrame(columns=['sentence_index','sentence','preprocessed_sentence','labels'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrD0-lTvOV8X",
        "outputId": "7702af54-fc6c-4325-bae0-275886c39c9f"
      },
      "source": [
        "for index,row in tqdm(val.iterrows()):\n",
        "  temp = pd.DataFrame(columns=['sentence_index','sentence','preprocessed_sentence','labels'])\n",
        "  sentence = row['Sentences']\n",
        "  preprocessed_sentences = row['preprocessed_sentences_labels']['preprocessed_sentences']\n",
        "  labels = row['preprocessed_sentences_labels']['labels']\n",
        "  for i in range(len(labels)):\n",
        "    data = pd.Series({'sentence_index': index,'sentence':sentence,\"preprocessed_sentence\": preprocessed_sentences[i], \"labels\": labels[i]})\n",
        "    temp = temp.append(data,ignore_index=True)\n",
        "  \n",
        "  val_2 = val_2.append(temp,ignore_index = True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7033it [01:11, 98.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__yWPqe6OWLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eeb438b-a6b9-4898-bdca-e36c6800f7d4"
      },
      "source": [
        "train.shape , val.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((63306, 4), (7033, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ZpU-84ms8P"
      },
      "source": [
        "train_2.to_csv('{}/train.gz'.format(dir_path), compression='gzip')\n",
        "val_2.to_csv('{}/val.gz'.format(dir_path), compression='gzip')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqREEBiAoFgf",
        "outputId": "e7ba0ec2-c2d6-4aaf-e596-b6d80c71221c"
      },
      "source": [
        "os.listdir(dir_path)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dev.pointer',\n",
              " 'test.pointer',\n",
              " 'train.pointer',\n",
              " '__MACOSX',\n",
              " 'train_df2.gz',\n",
              " 'val_df2.gz',\n",
              " 'dev.sent',\n",
              " 'dev.tup',\n",
              " 'relations.txt',\n",
              " 'test.sent',\n",
              " 'test.tup',\n",
              " 'train.sent',\n",
              " 'train.tup',\n",
              " 'Best_model.h5py',\n",
              " 'train.gz',\n",
              " 'val.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bCamsWUvGSZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}